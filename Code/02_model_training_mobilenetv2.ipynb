{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2c38da",
   "metadata": {},
   "source": [
    "# Cell 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Update this path to your specific folder\n",
    "DATA_PATH = r\"D:\\Machine Learning project\\Natural Images Project\\processed_images\"\n",
    "\n",
    "ORIGINAL_WIDTH = 256\n",
    "ORIGINAL_HEIGHT = 256\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d44e5a",
   "metadata": {},
   "source": [
    "# Cell 2: Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d62f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Full Dataset ---\n",
    "dataset = image_dataset_from_directory(\n",
    "    DATA_PATH,\n",
    "    seed=SEED,\n",
    "    image_size=(ORIGINAL_HEIGHT, ORIGINAL_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "class_names = dataset.class_names\n",
    "class_num = len(class_names)\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Number of Classes:\", class_num)\n",
    "\n",
    "# --- Define Split Function ---\n",
    "def get_dataset_partitions(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=SEED)\n",
    "    \n",
    "    train_size = int(ds_size * train_split)\n",
    "    val_size = int(ds_size * val_split)\n",
    "    \n",
    "    train_data = ds.take(train_size)\n",
    "    val_data = ds.skip(train_size).take(val_size)\n",
    "    test_data = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# --- Create Partitions ---\n",
    "train_data, val_data, test_data = get_dataset_partitions(dataset, train_split=0.7, val_split=0.15, test_split=0.15)\n",
    "\n",
    "print(f\"Training batches: {len(train_data)}\")\n",
    "print(f\"Validation batches: {len(val_data)}\")\n",
    "print(f\"Testing batches: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555355f",
   "metadata": {},
   "source": [
    "# Cell 3 visualizing the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8, 4, figsize=(12,24))\n",
    "\n",
    "# Flatten the axs array for easier iteration if needed, or use nested loops\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "# 1. Take one batch from the dataset\n",
    "for image_batch, label_batch in train_data.take(1):\n",
    "\n",
    "    # Plot on each subplot\n",
    "    for i, ax in enumerate(axs_flat):\n",
    "        ax.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        ax.set_title(class_names[label_batch[i]])\n",
    "        ax.grid(True) # Add a grid for better visualization\n",
    "        #ax.axis(\"off\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03c328",
   "metadata": {},
   "source": [
    "# Cell 4: Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d569b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimization ---\n",
    "# Cache keeps images in memory after the first epoch.\n",
    "# Prefetch prepares the next batch while the GPU is working on the current one.\n",
    "\n",
    "# Shuffle ONLY training data\n",
    "train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Do NOT shuffle validation/test data (keeps evaluation consistent)\n",
    "val_data = val_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe8a4d",
   "metadata": {},
   "source": [
    "# Cell 5: Preprocessing & Augmentation (Added This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ADDED: Define Rescaling and Augmentation ---\n",
    "\n",
    "# MobileNetV2 expects inputs in range [-1, 1].\n",
    "# This layer maps 0->-1 and 255->1.\n",
    "rescale = layers.Rescaling(1./127.5, offset=-1)\n",
    "\n",
    "# Specific data augmentation to prevent overfitting.\n",
    "# These layers are only active during training, not prediction.\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.06),\n",
    "    layers.RandomZoom(0.06),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d1c14",
   "metadata": {},
   "source": [
    "# Cell 6: Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_shape = (original_height, original_width, 3)\n",
    "\n",
    "# --- 1. Load the Pre-trained Base Model ---\n",
    "# We use MobileNetV2, but you could also use EfficientNetB0, ResNet50, etc.\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=input_img_shape,\n",
    "    include_top=False,  # Do not include the final classifier (1000 classes)\n",
    "    weights='imagenet'  # Load weights pre-trained on ImageNet\n",
    ")\n",
    "\n",
    "# --- 2. Freeze the Base Model ---\n",
    "# This stops its weights from being updated during initial training.\n",
    "# We only want to train our *new* layers.\n",
    "base_model.trainable = False\n",
    "\n",
    "# --- 3. Create Your New Model ---\n",
    "model_transfer = keras.Sequential([\n",
    "    keras.Input(shape=input_img_shape),\n",
    "    rescale,\n",
    "    data_augmentation,\n",
    "    base_model, # The frozen pre-trained base\n",
    "    \n",
    "    # --- New Classifier Head ---\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5), # Regularization\n",
    "    layers.Dense(128, activation='relu'), # A dense layer to learn from the features\n",
    "    layers.Dense(class_num, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159956dd",
   "metadata": {},
   "source": [
    "# Cell 7: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc43da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Compile ---\n",
    "model_transfer.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- 5. Train ---\n",
    "print(\"--- Training the new classifier head ---\")\n",
    "# Saving history to a variable so we can plot it\n",
    "history = model_transfer.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a2416",
   "metadata": {},
   "source": [
    "# Cell 8: Evaluation & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ff813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Test Evaluation ---\n",
    "print(\"Evaluating on Test Data...\")\n",
    "acc_on_test = model_transfer.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {acc_on_test[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbfb013",
   "metadata": {},
   "source": [
    "# Cell 9: Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e78f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Model ---\n",
    "model_transfer.save('MobileNetV2_classifier.keras')\n",
    "print(\"Model saved to MobileNetV2_classifier.keras\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
