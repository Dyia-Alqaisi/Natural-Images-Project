{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f2e2eb",
   "metadata": {},
   "source": [
    "# Cell 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps # ImageOps is critical for fixing rotation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your saved model file\n",
    "MODEL_PATH = r'D:\\Machine Learning project\\Natural Images Project\\PythonCode\\MobileNetV2_classifier.keras'\n",
    "\n",
    "# Path to the new image you want to test\n",
    "# You can change this path to test different images!\n",
    "NEW_IMAGE_PATH = r\"D:\\Machine Learning project\\Natural Images Project\\cars-dataset\\Nissan-Zamiad\\Nissan-Zamiad (3).jpg\"\n",
    "\n",
    "# Target size must match what you used during training (256x256)\n",
    "TARGET_SIZE = (256, 256)\n",
    "PADDING_COLOR = (0, 0, 0) # Black padding\n",
    "\n",
    "# --- Load Model & Define Classes ---\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "loaded_model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# IMPORTANT: These must match the alphabetical order of folders in your training set exactly.\n",
    "class_names = ['airplane', 'car', 'cat', 'dog', 'flower', 'fruit', 'motorbike', 'person']\n",
    "print(f\"Model loaded. Class labels: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad63f2",
   "metadata": {},
   "source": [
    "# Cell 2: Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee29ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_true_padding(img, target_size, padding_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Resizes an image to fit within the target size by adding padding.\n",
    "    Maintains the original aspect ratio to prevent distortion.\n",
    "    \"\"\"\n",
    "    # 1. Convert to RGB to handle PNGs with transparency or Grayscale images\n",
    "    if img.mode == 'RGBA':\n",
    "        # Create a solid background using the padding color\n",
    "        bg = Image.new('RGB', img.size, padding_color)\n",
    "        # Paste the image on top using alpha channel as mask\n",
    "        bg.paste(img, (0, 0), img.split()[-1])\n",
    "        img = bg\n",
    "    elif img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    # 2. Resize the image (thumbnail) so it fits inside the target box\n",
    "    # This maintains the aspect ratio (doesn't stretch the image)\n",
    "    img.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # 3. Create a new blank background image\n",
    "    new_img = Image.new(\"RGB\", target_size, padding_color)\n",
    "    \n",
    "    # 4. Paste the resized image into the center of the background\n",
    "    paste_x = (target_size[0] - img.width) // 2\n",
    "    paste_y = (target_size[1] - img.height) // 2\n",
    "    new_img.paste(img, (paste_x, paste_y))\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e642b",
   "metadata": {},
   "source": [
    "# Cell 3: Prediction & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load the Image ---\n",
    "if not os.path.exists(NEW_IMAGE_PATH):\n",
    "    print(f\"Error: Image not found at {NEW_IMAGE_PATH}\")\n",
    "else:\n",
    "    print(f\"Processing image: {NEW_IMAGE_PATH}\")\n",
    "    img = Image.open(NEW_IMAGE_PATH)\n",
    "\n",
    "    # --- 2. Fix Orientation (The Critical Fix) ---\n",
    "    # Phones often save images with EXIF rotation tags. \n",
    "    # This physically rotates the pixels so the model sees it upright.\n",
    "    img = ImageOps.exif_transpose(img) \n",
    "\n",
    "    # --- 3. Preprocess ---\n",
    "    # Apply the exact same padding logic used during training\n",
    "    img_processed = resize_with_true_padding(img, TARGET_SIZE, PADDING_COLOR)\n",
    "\n",
    "    # --- 4. Prepare for Model ---\n",
    "    # Convert PIL image to a NumPy array\n",
    "    img_array = tf.keras.utils.img_to_array(img_processed)\n",
    "    # Add a batch dimension (Models expect a batch of images, even if it's just 1)\n",
    "    # Shape becomes: (1, 256, 256, 3)\n",
    "    img_batch = np.expand_dims(img_array, axis=0) \n",
    "\n",
    "    # --- 5. Predict ---\n",
    "    prediction_scores = loaded_model.predict(img_batch, verbose=0)\n",
    "\n",
    "    # --- 6. Interpret Results ---\n",
    "    # Find the index with the highest score\n",
    "    predicted_class_index = np.argmax(prediction_scores[0])\n",
    "    # Get the name corresponding to that index\n",
    "    predicted_class_name = class_names[predicted_class_index]\n",
    "    # Get the confidence score (probability)\n",
    "    confidence_score = np.max(prediction_scores[0])\n",
    "\n",
    "    # --- 7. Display ---\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_array.astype(\"uint8\")) \n",
    "    plt.title(f\"Prediction: {predicted_class_name}\\nConfidence: {confidence_score * 100:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
